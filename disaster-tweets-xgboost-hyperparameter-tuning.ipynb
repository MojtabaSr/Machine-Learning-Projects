{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Import datasets and libraries**","metadata":{"execution":{"iopub.status.busy":"2021-07-13T15:49:41.044355Z","iopub.execute_input":"2021-07-13T15:49:41.044687Z","iopub.status.idle":"2021-07-13T15:49:41.051053Z","shell.execute_reply.started":"2021-07-13T15:49:41.044659Z","shell.execute_reply":"2021-07-13T15:49:41.050159Z"}}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom textblob import TextBlob\nfrom textblob import Word","metadata":{"execution":{"iopub.status.busy":"2021-07-13T16:58:43.578156Z","iopub.execute_input":"2021-07-13T16:58:43.578498Z","iopub.status.idle":"2021-07-13T16:58:43.584996Z","shell.execute_reply.started":"2021-07-13T16:58:43.578469Z","shell.execute_reply":"2021-07-13T16:58:43.584178Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-13T16:58:46.298806Z","iopub.execute_input":"2021-07-13T16:58:46.299299Z","iopub.status.idle":"2021-07-13T16:58:46.338042Z","shell.execute_reply.started":"2021-07-13T16:58:46.299269Z","shell.execute_reply":"2021-07-13T16:58:46.337180Z"},"trusted":true},"execution_count":66,"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train=train.drop(['id','keyword','location'],axis=1)\ntrain.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-13T16:58:48.555646Z","iopub.execute_input":"2021-07-13T16:58:48.555989Z","iopub.status.idle":"2021-07-13T16:58:48.572011Z","shell.execute_reply.started":"2021-07-13T16:58:48.555954Z","shell.execute_reply":"2021-07-13T16:58:48.570892Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 7613 entries, 0 to 7612\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   text    7613 non-null   object\n 1   target  7613 non-null   int64 \ndtypes: int64(1), object(1)\nmemory usage: 119.1+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"test=pd.read_csv('/kaggle/input/nlp-getting-started/test.csv').drop(['id','keyword','location'],axis=1)\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-13T16:58:50.803462Z","iopub.execute_input":"2021-07-13T16:58:50.803799Z","iopub.status.idle":"2021-07-13T16:58:50.825423Z","shell.execute_reply.started":"2021-07-13T16:58:50.803768Z","shell.execute_reply":"2021-07-13T16:58:50.824477Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"                                                text\n0                 Just happened a terrible car crash\n1  Heard about #earthquake is different cities, s...\n2  there is a forest fire at spot pond, geese are...\n3           Apocalypse lighting. #Spokane #wildfires\n4      Typhoon Soudelor kills 28 in China and Taiwan","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Just happened a terrible car crash</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Heard about #earthquake is different cities, s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>there is a forest fire at spot pond, geese are...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Apocalypse lighting. #Spokane #wildfires</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train.info(),test.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-13T16:58:52.808245Z","iopub.execute_input":"2021-07-13T16:58:52.808574Z","iopub.status.idle":"2021-07-13T16:58:52.832131Z","shell.execute_reply.started":"2021-07-13T16:58:52.808546Z","shell.execute_reply":"2021-07-13T16:58:52.831184Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 7613 entries, 0 to 7612\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   text    7613 non-null   object\n 1   target  7613 non-null   int64 \ndtypes: int64(1), object(1)\nmemory usage: 119.1+ KB\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3263 entries, 0 to 3262\nData columns (total 1 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   text    3263 non-null   object\ndtypes: object(1)\nmemory usage: 25.6+ KB\n","output_type":"stream"},{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"(None, None)"},"metadata":{}}]},{"cell_type":"markdown","source":"**Create two functions (one nested) that does the cleaning and processing the data**","metadata":{}},{"cell_type":"code","source":"def processRow(row):\n    \n    tweet = row\n    #Lower case\n    tweet.lower()\n    #Removes unicode strings like \"\\u002c\" and \"x96\"\n    tweet = re.sub(r'(\\\\u[0-9A-Fa-f]+)',\" \", tweet)\n    tweet = re.sub(r'[^\\x00-\\x7f]',\" \",tweet)\n    #convert any url to URL\n    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',tweet)\n    #Convert any @Username to \"AT_USER\"\n    tweet = re.sub('@[^\\s]+','AT_USER',tweet)\n    #Remove additional white spaces\n    tweet = re.sub('[\\s]+', ' ', tweet)\n    tweet = re.sub('[\\n]+', ' ', tweet)\n    #Remove not alphanumeric symbols white spaces\n    tweet = re.sub(r'[^\\w]', ' ', tweet)\n    #Removes hastag in front of a word \"\"\"\n    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n    #Replace #word with word\n    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n    #Remove :( or :)\n    tweet = tweet.replace(':)',\" \")\n    tweet = tweet.replace(':(',\" \")\n    #remove numbers\n    tweet = \"\".join([i for i in tweet if not i.isdigit()])\n    #remove multiple exclamation\n    tweet = re.sub(r\"(\\!)\\1+\", ' ', tweet)\n    #remove multiple question marks\n    tweet = re.sub(r\"(\\?)\\1+\", ' ', tweet)\n    #remove multistop\n    tweet = re.sub(r\"(\\.)\\1+\", ' ', tweet)\n    #lemma\n    from textblob import Word\n    tweet =\" \".join([Word(word).lemmatize() for word in tweet.split()])\n    tweet = tweet.strip('\\'\"')\n    #lowercase\n    tweet = tweet.lower()\n    tweet = tweet.split()\n    ps = PorterStemmer()\n    all_stopwords = stopwords.words('english')\n    tweet = [ps.stem(word) for word in tweet if not word in set(all_stopwords)]\n    tweet = ' '.join(tweet)\n    \n    \n    row = tweet\n    return row\n\ndef processData(dataset,predictor):\n    \n    corpus=[]\n    for i in range(0,len(dataset)):\n        tweet = processRow(predictor[i])\n        corpus.append(tweet)\n    return corpus\n\ncorpus_train=processData(train,train['text'])\ncorpus_test=processData(test,test['text'])","metadata":{"execution":{"iopub.status.busy":"2021-07-13T16:58:55.898159Z","iopub.execute_input":"2021-07-13T16:58:55.898494Z","iopub.status.idle":"2021-07-13T16:59:04.128584Z","shell.execute_reply.started":"2021-07-13T16:58:55.898466Z","shell.execute_reply":"2021-07-13T16:59:04.127653Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"**Use CountVectorizer to create a matrix of token counts. One for training and one for testing**","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features = 3000)\n\nX = cv.fit_transform(corpus_train).toarray()\ny=train.iloc[:,-1].values\n\n\nXt=cv.transform(corpus_test).toarray()\n\nX.shape,y.shape,Xt.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-13T16:59:07.912013Z","iopub.execute_input":"2021-07-13T16:59:07.912364Z","iopub.status.idle":"2021-07-13T16:59:08.227075Z","shell.execute_reply.started":"2021-07-13T16:59:07.912333Z","shell.execute_reply":"2021-07-13T16:59:08.226202Z"},"trusted":true},"execution_count":72,"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"((7613, 3000), (7613,), (3263, 3000))"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\nX_train.shape,X_test.shape,y_train.shape,y_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-13T16:59:10.097955Z","iopub.execute_input":"2021-07-13T16:59:10.098453Z","iopub.status.idle":"2021-07-13T16:59:10.180043Z","shell.execute_reply.started":"2021-07-13T16:59:10.098424Z","shell.execute_reply":"2021-07-13T16:59:10.179304Z"},"trusted":true},"execution_count":73,"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"((6090, 3000), (1523, 3000), (6090,), (1523,))"},"metadata":{}}]},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV\nxgb1 = xgb.XGBRegressor()\nparameters = {'objective':['reg:squarederror'],\n              'booster':['gbtree'],\n              'learning_rate': [0.05,0.2,0.25,0.3], #so called `eta` value\n              'max_depth': [5, 8, 10,12],\n              'n_estimators': [100]}\n\n#Use gridsearch with 2 folds for finding optimal parameters and vlaues\nxgb_grid = GridSearchCV(xgb1,\n                        parameters,\n                        cv = 2,\n                        n_jobs = 2,\n                        verbose=True)\n\nxgb_grid.fit(X_train,y_train)\nprint(xgb_grid.best_params_)\n\n#output: booster= 'gbtree', learning_rate= 0.3, max_depth= 5, n_estimators= 100, objective= 'reg:squarederror' ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instantiate an XGBoost object with hyperparameters\nxgb_reg = xgb.XGBRegressor(booster= 'gbtree', learning_rate= 0.3, max_depth= 5, n_estimators= 100, objective= 'reg:squarederror')\n# Train the model with train data sets\nxgb_reg.fit(X_train, y_train)\n\ny_pred = xgb_reg.predict(X_test) # Predictions\n\ny_pred[y_pred<0.5]=0\ny_pred[y_pred>0.5]=1\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\nprint(accuracy_score(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-07-13T16:59:27.112333Z","iopub.execute_input":"2021-07-13T16:59:27.112709Z","iopub.status.idle":"2021-07-13T16:59:50.829398Z","shell.execute_reply.started":"2021-07-13T16:59:27.112674Z","shell.execute_reply":"2021-07-13T16:59:50.828639Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"[[807  79]\n [218 419]]\n0.8049901510177282\n","output_type":"stream"}]},{"cell_type":"code","source":"y_pred_test=xgb_reg.predict(Xt)\n\ny_pred_test[y_pred_test<0.5]=0\ny_pred_test[y_pred_test>0.5]=1\n\ny_pred_test=y_pred_test.astype(int)\n\n\ntest_output=pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv')\noutput = pd.DataFrame({'id': test_output.id, 'target': y_pred_test.astype('str')})\noutput.to_csv(\"nlp_submission.csv\", index=False)\nprint('Submission done!')","metadata":{"execution":{"iopub.status.busy":"2021-07-13T16:59:59.195736Z","iopub.execute_input":"2021-07-13T16:59:59.196325Z","iopub.status.idle":"2021-07-13T16:59:59.272172Z","shell.execute_reply.started":"2021-07-13T16:59:59.196289Z","shell.execute_reply":"2021-07-13T16:59:59.271428Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"Submission done!\n","output_type":"stream"}]}]}